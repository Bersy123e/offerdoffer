import pandas as pd
import re
import logging
import numpy as np
from typing import List, Dict, Optional, Any, Tuple
import os

logger = logging.getLogger('commercial_proposal')

class CascadeProcessor:
    """
    –ö–∞—Å–∫–∞–¥–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–æ–≤.
    –ü—Ä–æ–±—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–µ—Ç–æ–¥–æ–≤ –ø–æ –æ—á–µ—Ä–µ–¥–∏:
    1. –≠–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–π (–±—ã—Å—Ç—Ä—ã–π, –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤).
    2. LLM (–º–µ–¥–ª–µ–Ω–Ω—ã–π, –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤) - –ø–æ–∫–∞ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω.
    """

    def __init__(self, llm: Optional[Any] = None):
        self.llm = llm
        self.cascade_log = []
        # –£–¥–∞–ª—è–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä—ã
        # self.level1_processor –∏ self.level2_processor –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã

    def process_file_cascade(self, file_path: str, file_name: str) -> Dict:
        logger.info(f"--- –ó–ê–ü–£–°–ö –ö–ê–°–ö–ê–î–ù–û–ô –û–ë–†–ê–ë–û–¢–ö–ò –¥–ª—è —Ñ–∞–π–ª–∞: {file_name} ---")
        self.cascade_log = [f"–ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {file_name}"]
        error_message = "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ. –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞."

        try:
            heuristic_result = self._process_with_heuristics(file_path)
            if heuristic_result.get('success'):
                logger.info("–£—Ä–æ–≤–µ–Ω—å 1 (–≠–≤—Ä–∏—Å—Ç–∏–∫–∞) —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ–∫ —Ç–æ–≤–∞—Ä—ã.")
                self.cascade_log.append("–£—Ä–æ–≤–µ–Ω—å 1 (–≠–≤—Ä–∏—Å—Ç–∏–∫–∞) –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —É—Å–ø–µ—à–Ω–æ.")
                heuristic_result['final_method'] = '–≠–≤—Ä–∏—Å—Ç–∏–∫–∞'
                heuristic_result['cascade_log'] = self.cascade_log
                return heuristic_result
            else:
                self.cascade_log.extend(heuristic_result.get('log', []))
                self.cascade_log.append("–£—Ä–æ–≤–µ–Ω—å 1 (–≠–≤—Ä–∏—Å—Ç–∏–∫–∞) –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞.")
                logger.warning("–£—Ä–æ–≤–µ–Ω—å 1 (–≠–≤—Ä–∏—Å—Ç–∏–∫–∞) –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞.")
                error_message = heuristic_result.get('error', error_message)
        except Exception as e:
            logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –Ω–∞ –£—Ä–æ–≤–Ω–µ 1 (–≠–≤—Ä–∏—Å—Ç–∏–∫–∞): {e}", exc_info=True)
            self.cascade_log.append(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –Ω–∞ –£—Ä–æ–≤–Ω–µ 1: {e}")
            error_message = f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}"

        return {"success": False, "products": [], "error": error_message, "cascade_log": self.cascade_log}

    def _process_with_heuristics(self, file_path: str) -> Dict:
        log = []
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ª–∏—Å—Ç–æ–≤ –≤ Excel
            file_ext = os.path.splitext(file_path)[1].lower()
            all_products = []
            
            if file_ext in ['.xlsx', '.xls']:
                excel_file = pd.ExcelFile(file_path)
                sheet_names = excel_file.sheet_names
                log.append(f"–§–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç {len(sheet_names)} –ª–∏—Å—Ç(–æ–≤): {sheet_names}")
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –ª–∏—Å—Ç
                for sheet_name in sheet_names:
                    log.append(f"\n--- –û–±—Ä–∞–±–æ—Ç–∫–∞ –ª–∏—Å—Ç–∞ '{sheet_name}' ---")
                    try:
                        df = pd.read_excel(file_path, sheet_name=sheet_name, header=None)
                        log.append(f"–õ–∏—Å—Ç '{sheet_name}' –ø—Ä–æ—á–∏—Ç–∞–Ω: {df.shape[0]} —Å—Ç—Ä–æ–∫, {df.shape[1]} –∫–æ–ª–æ–Ω–æ–∫")
                        
                        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ª–∏—Å—Ç —Ç–µ–º–∏ –∂–µ –º–µ—Ç–æ–¥–∞–º–∏
                        products = self._process_single_sheet(df, sheet_name, log)
                        all_products.extend(products)
                        
                    except Exception as sheet_error:
                        log.append(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ª–∏—Å—Ç–∞ '{sheet_name}': {sheet_error}")
                        continue
                
                if all_products:
                    log.append(f"\n–í—Å–µ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤ —Å–æ –≤—Å–µ—Ö –ª–∏—Å—Ç–æ–≤: {len(all_products)}")
                    return {"success": True, "products": all_products, "log": log}
                else:
                    return {"success": False, "products": [], "log": log, "error": "–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∏ –Ω–∞ –æ–¥–Ω–æ–º –ª–∏—Å—Ç–µ"}
            else:
                # –î–ª—è –¥—Ä—É–≥–∏—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ —á–∏—Ç–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω–æ
                df = pd.read_excel(file_path, header=None)
                log.append(f"–§–∞–π–ª {file_path} —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ—á–∏—Ç–∞–Ω –≤ DataFrame.")
                products = self._process_single_sheet(df, "main", log)
                return {"success": True, "products": products, "log": log} if products else {"success": False, "products": [], "log": log, "error": "–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤"}
                
        except Exception as e:
            log.append(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª: {e}")
            return {"success": False, "products": [], "log": log, "error": f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è: {e}"}
    
    def _process_single_sheet(self, df: pd.DataFrame, sheet_name: str, log: List[str]) -> List[Dict]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –ª–∏—Å—Ç–∞ Excel"""
        header_row_index, header = self._find_header_row(df, log)
        if header_row_index is None:
            log.append(f"–õ–∏—Å—Ç '{sheet_name}': –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å—Ç—Ä–æ–∫—É –∑–∞–≥–æ–ª–æ–≤–∫–∞.")
            return []  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫, –∞ –Ω–µ —Å–ª–æ–≤–∞—Ä—å
        
        df.columns = [f"col_{i}" for i in range(len(df.columns))]
        header_map = {f"col_{i}": str(h) for i, h in enumerate(header)}
        
        data_df = df.iloc[header_row_index + 1:].reset_index(drop=True)
        log.append(f"–õ–∏—Å—Ç '{sheet_name}': –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã, –Ω–∞—á–∏–Ω–∞—è —Å–æ —Å—Ç—Ä–æ–∫–∏ {header_row_index + 1}.")

        name_col, price_col, stock_col = self._map_columns(header_map, data_df, log)

        if not name_col or not price_col:
            log.append(f"–õ–∏—Å—Ç '{sheet_name}': –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ' –∏–ª–∏ '–¶–µ–Ω–∞'.")
            return []  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫

        products = self._extract_products_with_subheaders(data_df, name_col, price_col, stock_col, log, header_map)

        if not products:
            log.append(f"–õ–∏—Å—Ç '{sheet_name}': –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞.")
            return []
        
        log.append(f"–õ–∏—Å—Ç '{sheet_name}': –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(products)} —Ç–æ–≤–∞—Ä–æ–≤.")
        return products

    def _find_header_row(self, df: pd.DataFrame, log: List[str]) -> Tuple[Optional[int], Optional[List[str]]]:
        header_keywords = ['–Ω–∞–∏–º–µ–Ω', '—Ç–æ–≤–∞—Ä', '—Ü–µ–Ω–∞', '–∫–æ–ª-–≤–æ', '–æ—Å—Ç–∞—Ç', '–∞—Ä—Ç–∏–∫—É–ª', '—Ä—É–±', '–≥–æ—Å—Ç', '–Ω-—Ä–∞', '–æ–ø–∏—Å–∞–Ω–∏–µ']
        best_row_index = -1
        max_matches = 0

        for i, row in df.head(20).iterrows():
            row_str = ' '.join(str(x) for x in row.dropna() if x).lower()
            if not row_str: continue
            
            matches = sum(1 for kw in header_keywords if kw in row_str)
            
            if matches > 1 and matches > max_matches:
                max_matches = matches
                best_row_index = i
        
        if best_row_index != -1:
            log.append(f"–ù–∞–π–¥–µ–Ω–∞ —Å—Ç—Ä–æ–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞ (–∏–Ω–¥–µ–∫—Å {best_row_index}) —Å {max_matches} —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è–º–∏.")
            return best_row_index, list(df.iloc[best_row_index])
        
        log.append("–°—Ç—Ä–æ–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞.")
        return 0, list(df.iloc[0])

    def _map_columns(self, header_map: Dict, df: pd.DataFrame, log: List[str]) -> Tuple[Optional[str], Optional[str], Optional[str]]:
        price_kw = ['—Ü–µ–Ω–∞', 'price', '—Å—Ç–æ–∏–º', 'cost', 'value', '—Ä—É–±', 'rub', '—Å—É–º–º–∞']
        stock_kw = ['–æ—Å—Ç–∞—Ç', '–∫–æ–ª-–≤–æ', '–Ω–∞–ª–∏—á', 'stock', 'qty', 'amount', 'balance', '–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ', '—Å–∫–ª–∞–¥']
        name_kw = ['–Ω–∞–∏–º–µ–Ω', '—Ç–æ–≤–∞—Ä', 'product', 'item', '–æ–ø–∏—Å–∞–Ω', 'nomenkl', '–Ω–∞–∑–≤', '–ø—Ä–æ–¥—É–∫—Ç']

        def find_header(keywords):
            for col_idx, header_name in header_map.items():
                if any(k in str(header_name).lower() for k in keywords):
                    return col_idx
            return None

        name_col = find_header(name_kw) or 'col_0'
        price_col = find_header(price_kw)
        stock_col = find_header(stock_kw)
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –∫–æ–ª–æ–Ω–∫—É —Å —Ü–µ–Ω–æ–π –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º, –ø–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø–æ –¥–∞–Ω–Ω—ã–º
        if not price_col:
            log.append("–ù–µ –Ω–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ —Ü–µ–Ω—ã –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º. –ü—Ä–æ–±—É–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É...")
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 10 —Å—Ç—Ä–æ–∫ –¥–∞–Ω–Ω—ã—Ö
            for col_idx in header_map.keys():
                if col_idx == name_col:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ–ª–æ–Ω–∫—É —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º
                    continue
                    
                price_like_count = 0
                for i in range(min(10, len(df))):
                    val = str(df.iloc[i].get(col_idx, '')).strip()
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ—Ö–æ–∂–µ –ª–∏ –Ω–∞ —Ü–µ–Ω—É
                    if re.search(r'\d+[\s,\.]*\d*', val) and not re.search(r'[–∞-—è–ê-–Øa-zA-Z]{3,}', val):
                        price_like_count += 1
                
                if price_like_count >= 5:  # –ï—Å–ª–∏ –±–æ–ª—å—à–µ –ø–æ–ª–æ–≤–∏–Ω—ã –∑–Ω–∞—á–µ–Ω–∏–π –ø–æ—Ö–æ–∂–∏ –Ω–∞ —Ü–µ–Ω—ã
                    price_col = col_idx
                    log.append(f"–í–µ—Ä–æ—è—Ç–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞ —Ü–µ–Ω—ã –Ω–∞–π–¥–µ–Ω–∞ –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É: {col_idx}")
                    break
        
        log.append(f"–ü–µ—Ä–≤–∏—á–Ω—ã–π –º–∞–ø–ø–∏–Ω–≥: Name='{header_map.get(name_col)}' ({name_col}), Price='{header_map.get(price_col)}' ({price_col}), Stock='{header_map.get(stock_col)}' ({stock_col})")
        
        return name_col, price_col, stock_col

    def _extract_products_with_subheaders(self, df: pd.DataFrame, name_col: str, price_col: str, stock_col: Optional[str], log: List[str], header_map: Dict) -> List[Dict]:
        products = []
        current_subheader = ""
        for index, row in df.iterrows():
            name = str(row.get(name_col, "")).strip()
            
            is_subheader = name and all(pd.isna(v) or str(v).strip() == "" for k, v in row.items() if k != name_col)
            
            if is_subheader:
                current_subheader = name
                log.append(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–æ–∫: '{current_subheader}'")
                continue

            if not name: continue

            full_name = f"{current_subheader} {name}".strip()
            
            price = 0
            price_raw = str(row.get(price_col, "")).strip()
            if price_raw and price_raw not in ['nan', 'None', '-', '']:
                # –õ–æ–≥–∏—Ä—É–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ü–µ–Ω—ã –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                logger.debug(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ü–µ–Ω—É: '{price_raw}'")
                
                # –£–¥–∞–ª—è–µ–º –≤—Å–µ –ø—Ä–æ–±–µ–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –≤–∫–ª—é—á–∞—è –Ω–µ—Ä–∞–∑—Ä—ã–≤–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
                price_raw = price_raw.replace('\xa0', ' ').replace('\u00a0', ' ')
                
                # –ï—Å–ª–∏ —Ü–µ–Ω–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥—Ä–æ–±—å —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª (–Ω–∞–ø—Ä–∏–º–µ—Ä "1 234,56")
                # –∏–ª–∏ —á–µ—Ä–µ–∑ —Ç–æ—á–∫—É –∫–∞–∫ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å —Ç—ã—Å—è—á (–Ω–∞–ø—Ä–∏–º–µ—Ä "1.234,56")
                price_raw = price_raw.replace(' ', '')
                
                # –ó–∞–º–µ–Ω—è–µ–º –∑–∞–ø—è—Ç—É—é –Ω–∞ —Ç–æ—á–∫—É –¥–ª—è –¥–µ—Å—è—Ç–∏—á–Ω—ã—Ö
                if ',' in price_raw and '.' in price_raw:
                    # –ï—Å–ª–∏ –µ—Å—Ç—å –∏ —Ç–æ—á–∫–∞ –∏ –∑–∞–ø—è—Ç–∞—è, –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º —á—Ç–æ —Ç–æ—á–∫–∞ - —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å —Ç—ã—Å—è—á
                    price_raw = price_raw.replace('.', '').replace(',', '.')
                else:
                    price_raw = price_raw.replace(',', '.')
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–∞ –∏ —Ç–æ—á–∫—É
                clean_price = re.sub(r'[^\d\.]', '', price_raw)
                
                if clean_price:
                    try:
                        price = float(clean_price)
                        logger.debug(f"–£—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω–∞ —Ü–µ–Ω–∞: {price}")
                    except (ValueError, TypeError) as e:
                        logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —Ü–µ–Ω—É '{clean_price}': {e}")
            
            stock = 100
            if stock_col and pd.notna(row.get(stock_col)):
                stock_raw = str(row[stock_col]).lower().strip()
                if any(w in stock_raw for w in ['–Ω–µ—Ç', '0', '–ø–æ–¥ –∑–∞–∫–∞–∑', '–æ–∂–∏–¥', '–æ—Ç—Å—É—Ç']): stock = 0
                elif any(w in stock_raw for w in ['–µ—Å—Ç—å', '–≤ –Ω–∞–ª–∏—á–∏–∏', '–Ω–∞–ª–∏—á', '–º–Ω–æ–≥–æ']): stock = 100
                else:
                    stock_numbers = re.findall(r'\d+', stock_raw)
                    if stock_numbers: stock = int(stock_numbers[0])

            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–≤–∞—Ä –¥–∞–∂–µ –µ—Å–ª–∏ —Ü–µ–Ω–∞ = 0 (–≤–æ–∑–º–æ–∂–Ω–æ, —ç—Ç–æ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞)
            # –ù–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –±–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è
            if full_name and full_name.strip():
                products.append({"name": full_name, "price": price, "stock": stock})
                if price == 0:
                    logger.warning(f"–¢–æ–≤–∞—Ä —Å –Ω—É–ª–µ–≤–æ–π —Ü–µ–Ω–æ–π: {full_name[:50]}...")
        
        log.append(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(products)} —Ç–æ–≤–∞—Ä–æ–≤.")
        return products
    
    def get_cascade_summary(self, result: Dict) -> str:
        summary_lines = [
            f"–§–∏–Ω–∞–ª—å–Ω—ã–π —É—Å–ø–µ—à–Ω—ã–π –º–µ—Ç–æ–¥: {result.get('final_method', '–ù–µ–∏–∑–≤–µ—Å—Ç–µ–Ω')}",
            f"–ò–∑–≤–ª–µ—á–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(result.get('products', []))}",
            "--- –õ–æ–≥ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è ---",
            f"–°—Ç–∞—Ç—É—Å: {'–£—Å–ø–µ—Ö' if result.get('success') else '–ù–µ—É–¥–∞—á–∞'}"
        ]
        summary_lines.extend(result.get('cascade_log', ['–õ–æ–≥ –ø—É—Å—Ç.']))
        summary_lines.extend(result.get('log', []))
        return "\n".join(summary_lines)

    def _read_file_safely(self, file_path: str) -> Optional[pd.DataFrame]:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —á—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞"""
        try:
            file_ext = os.path.splitext(file_path)[1].lower()
            
            if file_ext == '.csv':
                # –î–ª—è CSV –ø—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
                for encoding in ['utf-8', 'cp1251', 'latin1']:
                    try:
                        return pd.read_csv(file_path, encoding=encoding, dtype=str)
                    except:
                        continue
                        
            elif file_ext in ['.xlsx', '.xls']:
                # –î–ª—è Excel –ø—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –¥–≤–∏–∂–∫–∏
                if file_ext == '.xls':
                    try:
                        return pd.read_excel(file_path, header=None, dtype=str, engine='xlrd')
                    except:
                        try:
                            return pd.read_excel(file_path, header=None, dtype=str, engine='openpyxl')
                        except:
                            return pd.read_excel(file_path, header=None, dtype=str)
                else:
                    return pd.read_excel(file_path, header=None, dtype=str)
                    
            return None
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file_path}: {e}")
            return None
    
    def _select_best_overall_result(self, level1_result: Dict, level2_result: Dict) -> Optional[Dict]:
        """–í—ã–±–æ—Ä –ª—É—á—à–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∏–∑ –≤—Å–µ—Ö —É—Ä–æ–≤–Ω–µ–π"""
        candidates = []
        
        if level1_result.get('success') and level1_result.get('products'):
            candidates.append({
                'method': 'level1_smart',
                'products': level1_result['products'],
                'count': len(level1_result['products'])
            })
            
        if level2_result.get('success') and level2_result.get('products'):
            candidates.append({
                'method': 'level2_bruteforce', 
                'products': level2_result['products'],
                'count': len(level2_result['products'])
            })
        
        if not candidates:
            return None
            
        # –í—ã–±–∏—Ä–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Ç–æ–≤–∞—Ä–æ–≤
        best = max(candidates, key=lambda x: x['count'])
        return best
        
    # –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω, —Ç–∞–∫ –∫–∞–∫ –æ–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ level1_processor –∏ level2_processor
    # def process_file_cascade(self, file_path: str, file_name: str = "") -> Dict:
    #     """
    #     –ö–∞—Å–∫–∞–¥–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ —Å —Ç—Ä–µ–º—è —É—Ä–æ–≤–Ω—è–º–∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
    #     """
    #     logger.info(f"üéØ –ö–ê–°–ö–ê–î–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê: {file_name}")
    #     
    #     result = {
    #         'success': False,
    #         'final_method': None,
    #         'products': [],
    #         'cascade_log': [],
    #         'all_attempts': {}
    #     }
    #     
    #     try:
    #         # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä—ã
    #         df = self._read_file_safely(file_path)
    #         if df is None:
    #             result['cascade_log'].append("‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞")
    #             return result
    #         
    #         # –£–†–û–í–ï–ù–¨ 1: –£–ú–ù–ê–Ø –°–ò–°–¢–ï–ú–ê
    #         logger.info("üî• –£–†–û–í–ï–ù–¨ 1: –£–º–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞")
    #         level1_result = self.level1_processor.process_price_list(df, file_name)
    #         result['all_attempts']['level1'] = level1_result
    #         
    #         if level1_result['success'] and len(level1_result['products']) >= 5:
    #             # –£—Å–ø–µ—Ö –Ω–∞ —É—Ä–æ–≤–Ω–µ 1!
    #             result['success'] = True
    #             result['final_method'] = 'level1_smart'
    #             result['products'] = level1_result['products']
    #             result['cascade_log'].append(f"‚úÖ –£–†–û–í–ï–ù–¨ 1 –£–°–ü–ï–•: {len(level1_result['products'])} —Ç–æ–≤–∞—Ä–æ–≤")
    #             logger.info(f"‚úÖ –£—Ä–æ–≤–µ–Ω—å 1 —É—Å–ø–µ—à–µ–Ω: {len(level1_result['products'])} —Ç–æ–≤–∞—Ä–æ–≤")
    #             return result
    #         else:
    #             result['cascade_log'].append(f"‚ö†Ô∏è –£–†–û–í–ï–ù–¨ 1: {len(level1_result.get('products', []))} —Ç–æ–≤–∞—Ä–æ–≤ (–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ)")
    #             
    #         # –£–†–û–í–ï–ù–¨ 2: –ë–†–£–¢–§–û–†–° –ê–ù–ê–õ–ò–ó
    #         logger.info("üî• –£–†–û–í–ï–ù–¨ 2: –ë—Ä—É—Ç—Ñ–æ—Ä—Å –∞–Ω–∞–ª–∏–∑")
    #         level2_result = self.level2_processor.process_complex_file(file_path, file_name)
    #         result['all_attempts']['level2'] = level2_result
    #         
    #         if level2_result['success'] and len(level2_result['products']) > 0:
    #             # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —É—Ä–æ–≤–Ω—è 1 –∏ 2
    #             level1_count = len(level1_result.get('products', []))
    #             level2_count = len(level2_result['products'])
    #             
    #             if level2_count > level1_count:
    #                 # –£—Ä–æ–≤–µ–Ω—å 2 –ª—É—á—à–µ
    #                 result['success'] = True
    #                 result['final_method'] = 'level2_bruteforce'
    #                 result['products'] = level2_result['products']
    #                 result['cascade_log'].append(f"‚úÖ –£–†–û–í–ï–ù–¨ 2 –õ–£–ß–®–ï: {level2_count} —Ç–æ–≤–∞—Ä–æ–≤ (vs {level1_count})")
    #                 logger.info(f"‚úÖ –£—Ä–æ–≤–µ–Ω—å 2 –ª—É—á—à–µ: {level2_count} vs {level1_count} —Ç–æ–≤–∞—Ä–æ–≤")
    #                 return result
    #             elif level1_count > 0:
    #                 # –£—Ä–æ–≤–µ–Ω—å 1 –≤—Å–µ –∂–µ –ª—É—á—à–µ
    #                 result['success'] = True  
    #                 result['final_method'] = 'level1_smart'
    #                 result['products'] = level1_result['products']
    #                 result['cascade_log'].append(f"‚úÖ –£–†–û–í–ï–ù–¨ 1 –õ–£–ß–®–ï: {level1_count} —Ç–æ–≤–∞—Ä–æ–≤ (vs {level2_count})")
    #                 return result
    #         else:
    #             result['cascade_log'].append(f"‚ö†Ô∏è –£–†–û–í–ï–ù–¨ 2: {len(level2_result.get('products', []))} —Ç–æ–≤–∞—Ä–æ–≤")
    #             
    #         # –£–†–û–í–ï–ù–¨ 3: –ü–û–õ–ù–´–ô LLM –ê–ù–ê–õ–ò–ó (–ø–æ–∫–∞ –∑–∞–≥–ª—É—à–∫–∞)
    #         logger.info("üî• –£–†–û–í–ï–ù–¨ 3: –ü–æ–ª–Ω—ã–π LLM –∞–Ω–∞–ª–∏–∑")
    #         result['cascade_log'].append("‚è≥ –£–†–û–í–ï–ù–¨ 3: –¢—Ä–µ–±—É–µ—Ç —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏")
    #         
    #         # –ï—Å–ª–∏ –¥–æ—à–ª–∏ —Å—é–¥–∞ - –±–µ—Ä–µ–º –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑ —É—Ä–æ–≤–Ω–µ–π 1-2
    #         best_result = self._select_best_overall_result(level1_result, level2_result)
    #         if best_result:
    #             result['success'] = True
    #             result['final_method'] = best_result['method']
    #             result['products'] = best_result['products']
    #             result['cascade_log'].append(f"‚úÖ –õ–£–ß–®–ò–ô –†–ï–ó–£–õ–¨–¢–ê–¢: {best_result['method']} - {len(best_result['products'])} —Ç–æ–≤–∞—Ä–æ–≤")
    #         else:
    #             result['cascade_log'].append("‚ùå –í–°–ï –£–†–û–í–ù–ò –ù–ï–£–°–ü–ï–®–ù–´")
    #             
    #     except Exception as e:
    #         logger.error(f"–û—à–∏–±–∫–∞ –∫–∞—Å–∫–∞–¥–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
    #         result['cascade_log'].append(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {str(e)}")
    #         
    #     return result 